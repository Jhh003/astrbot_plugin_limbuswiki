"""
Limbus Company Guide Plugin for AstrBot
A RAG-based game guide query plugin for Limbus Company
"""
import os
import asyncio
from datetime import datetime
from typing import Optional, Dict, Set

from astrbot.api.event import filter, AstrMessageEvent
from astrbot.api.star import Context, Star, StarTools, register
from astrbot.api import logger, AstrBotConfig

from .core.database import Database
from .core.chunker import Chunker
from .core.tagger import Tagger
from .core.searcher import Searcher
from .core.prompts import (
    PromptBuilder, 
    DOCUMENT_TEMPLATE, 
    HELP_TEXT, 
    STATUS_TEMPLATE,
    IMPORT_START_TEXT,
    IMPORT_SUCCESS_TEMPLATE
)


@register(
    "astrbot_plugin_limbuswiki",
    "Jhh003",
    "Limbus Companyï¼ˆè¾¹ç‹±å·´å£«ï¼‰æ¸¸æˆæ”»ç•¥æŸ¥è¯¢æ’ä»¶ï¼Œæ”¯æŒRAGæ£€ç´¢å’ŒWebUIç®¡ç†",
    "1.0.0",
    "https://github.com/Jhh003/astrbot_plugin_limbuswiki"
)
class LimbusGuidePlugin(Star):
    """Limbus Company game guide query plugin with RAG support"""
    
    def __init__(self, context: Context, config: AstrBotConfig):
        super().__init__(context)
        self.context = context
        self.config = config
        
        # Get plugin data directory
        self.data_dir = StarTools.get_data_dir("astrbot_plugin_limbuswiki")
        self.db_path = os.path.join(self.data_dir, "limbus_guide.db")
        
        # Configuration with defaults
        self.top_k = config.get("top_k", 6)
        self.chunk_size = config.get("chunk_size", 800)
        self.overlap = config.get("overlap", 120)
        self.group_boost = config.get("group_boost", 1.2)
        
        # WebUI configuration
        self.webui_enabled = config.get("webui_enabled", True)
        self.webui_host = config.get("webui_host", "0.0.0.0")
        self.webui_port = config.get("webui_port", 8765)
        self.webui_token = config.get("webui_token", "")
        
        # Initialize components (will be set in initialize())
        self.db: Optional[Database] = None
        self.chunker: Optional[Chunker] = None
        self.tagger: Optional[Tagger] = None
        self.searcher: Optional[Searcher] = None
        self.webui = None
        
        # Import session management: {unified_msg_origin: session_data}
        self.import_sessions: Dict[str, dict] = {}
        
    async def initialize(self):
        """Initialize plugin components"""
        logger.info("Initializing Limbus Guide Plugin...")
        
        # Initialize database
        self.db = Database(self.db_path)
        await self.db.init()
        
        # Initialize processing components
        self.chunker = Chunker(chunk_size=self.chunk_size, overlap=self.overlap)
        self.tagger = Tagger()
        self.searcher = Searcher()
        
        # Load existing data into searcher
        await self._rebuild_search_index()
        
        # Load aliases
        alias_map = await self.db.get_alias_map()
        self.searcher.update_aliases(alias_map)
        
        # Start WebUI server
        if self.webui_enabled:
            await self._start_webui()
        
        logger.info("Limbus Guide Plugin initialized successfully")
    
    async def _rebuild_search_index(self, group_id: Optional[str] = None):
        """Rebuild search index from database"""
        chunks = await self.db.get_all_chunks_for_search(group_id)
        self.searcher.update_chunks(chunks)
        logger.info(f"Search index rebuilt with {len(chunks)} chunks")
    
    async def _start_webui(self):
        """Start the WebUI server"""
        try:
            from .webui.server import WebUIServer
            
            webui_config = {
                'webui_enabled': self.webui_enabled,
                'webui_host': self.webui_host,
                'webui_port': self.webui_port,
                'webui_token': self.webui_token,
                'top_k': self.top_k,
                'chunk_size': self.chunk_size,
                'overlap': self.overlap,
                'group_boost': self.group_boost,
            }
            
            self.webui = WebUIServer(
                db=self.db,
                chunker=self.chunker,
                tagger=self.tagger,
                searcher=self.searcher,
                config=webui_config,
                on_index_update=self._rebuild_search_index
            )
            
            await self.webui.start()
            
            # Store generated token if not configured
            if not self.webui_token:
                self.webui_token = self.webui.get_token()
            
            logger.info(f"WebUI started at http://{self.webui_host}:{self.webui_port}")
            logger.info(f"WebUI Token: {self.webui_token}")
            
        except ImportError as e:
            logger.warning(f"WebUI dependencies not available: {e}")
            logger.warning("WebUI is disabled. Install fastapi and uvicorn to enable.")
        except Exception as e:
            logger.error(f"Failed to start WebUI: {e}")
    
    # ============ Command Handlers ============
    
    @filter.command("guide")
    async def guide_command(self, event: AstrMessageEvent):
        """ä¸»æŒ‡ä»¤è·¯ç”±"""
        message = event.message_str.strip()
        parts = message.split(maxsplit=2)
        
        if len(parts) < 2:
            # Just "/guide" - show help
            yield event.plain_result(HELP_TEXT)
            return
        
        subcommand = parts[1].lower()
        args = parts[2] if len(parts) > 2 else ""
        
        if subcommand == "help":
            yield event.plain_result(HELP_TEXT)
        elif subcommand == "template":
            yield event.plain_result(DOCUMENT_TEMPLATE)
        elif subcommand == "status":
            async for result in self._handle_status(event):
                yield result
        elif subcommand == "import":
            async for result in self._handle_import_start(event):
                yield result
        elif subcommand == "clear":
            async for result in self._handle_clear(event):
                yield result
        elif subcommand == "mode":
            async for result in self._handle_mode(event, args):
                yield result
        else:
            yield event.plain_result(f"æœªçŸ¥å­å‘½ä»¤: {subcommand}\nä½¿ç”¨ /guide help æŸ¥çœ‹å¸®åŠ©")
    
    async def _handle_status(self, event: AstrMessageEvent):
        """Handle /guide status command"""
        group_id = event.get_group_id() or "private"
        is_admin = event.is_admin()
        
        # Get stats
        stats = await self.db.get_stats(group_id)
        settings = await self.db.get_group_settings(group_id)
        
        # Format last import time
        last_import = settings.get('last_import_at')
        if last_import:
            last_import = last_import[:19]
        else:
            last_import = "ä»æœªå¯¼å…¥"
        
        # WebUI info (only for admins)
        webui_info = ""
        if is_admin and self.webui_enabled and self.webui:
            webui_info = f"""
**WebUIç®¡ç†**ï¼š
- åœ°å€ï¼š{self.webui.get_url()}
- Tokenï¼š{self.webui_token}
- âš ï¸ è¯·å‹¿æ³„éœ²Tokenï¼"""
        elif is_admin:
            webui_info = "**WebUI**ï¼šæœªå¯ç”¨"
        
        status_text = STATUS_TEMPLATE.format(
            group_id=group_id,
            default_mode=settings.get('default_mode', 'simple'),
            last_import=last_import,
            global_docs=stats['global']['doc_count'],
            global_chunks=stats['global']['chunk_count'],
            group_docs=stats['group']['doc_count'],
            group_chunks=stats['group']['chunk_count'],
            top_k=self.top_k,
            chunk_size=self.chunk_size,
            overlap=self.overlap,
            webui_info=webui_info
        )
        
        yield event.plain_result(status_text)
    
    async def _handle_import_start(self, event: AstrMessageEvent):
        """Handle /guide import command - start import session"""
        # Check admin permission
        if not event.is_admin():
            yield event.plain_result("âŒ ä»…ç®¡ç†å‘˜å¯ä»¥å¯¼å…¥æ”»ç•¥æ–‡æ¡£")
            return
        
        umo = event.unified_msg_origin
        group_id = event.get_group_id() or "private"
        
        # Create import session
        self.import_sessions[umo] = {
            'group_id': group_id,
            'texts': [],
            'started_at': datetime.now(),
            'timeout': 60
        }
        
        yield event.plain_result(IMPORT_START_TEXT)
    
    async def _handle_clear(self, event: AstrMessageEvent):
        """Handle /guide clear command"""
        if not event.is_admin():
            yield event.plain_result("âŒ ä»…ç®¡ç†å‘˜å¯ä»¥æ¸…ç©ºçŸ¥è¯†åº“")
            return
        
        group_id = event.get_group_id() or "private"
        
        # Clear group-specific documents only
        await self.db.clear_documents(scope='group', group_id=group_id)
        await self._rebuild_search_index()
        
        yield event.plain_result(f"âœ… å·²æ¸…ç©ºç¾¤ {group_id} çš„è¦†ç›–çŸ¥è¯†åº“")
    
    async def _handle_mode(self, event: AstrMessageEvent, args: str):
        """Handle /guide mode command"""
        group_id = event.get_group_id() or "private"
        
        if not args:
            # Show current mode
            settings = await self.db.get_group_settings(group_id)
            current_mode = settings.get('default_mode', 'simple')
            yield event.plain_result(f"å½“å‰é»˜è®¤å›ç­”æ¨¡å¼ï¼š{current_mode}")
            return
        
        mode = args.lower().strip()
        if mode not in ('simple', 'detail'):
            yield event.plain_result("âŒ æ¨¡å¼åªèƒ½æ˜¯ simple æˆ– detail")
            return
        
        await self.db.update_group_settings(group_id, default_mode=mode)
        yield event.plain_result(f"âœ… å·²å°†é»˜è®¤å›ç­”æ¨¡å¼è®¾ç½®ä¸ºï¼š{mode}")
    
    # ============ Import Session Handlers ============
    
    @filter.command("done")
    async def handle_done(self, event: AstrMessageEvent):
        """Handle /done command to finish import"""
        umo = event.unified_msg_origin
        
        if umo not in self.import_sessions:
            yield event.plain_result("å½“å‰æ²¡æœ‰è¿›è¡Œä¸­çš„å¯¼å…¥ä¼šè¯")
            return
        
        session = self.import_sessions[umo]
        texts = session['texts']
        group_id = session['group_id']
        
        if not texts:
            del self.import_sessions[umo]
            yield event.plain_result("âŒ æ²¡æœ‰æ”¶åˆ°ä»»ä½•æ–‡æœ¬å†…å®¹ï¼Œå¯¼å…¥å·²å–æ¶ˆ")
            return
        
        # Combine all texts
        full_text = "\n\n".join(texts)
        doc_name = f"guide_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
        
        # Process document
        try:
            doc_id = await self.db.add_document(
                name=doc_name,
                raw_text=full_text,
                scope='group',
                group_id=group_id
            )
            
            # Chunk and tag
            chunks = self.chunker.process_document(full_text, doc_name)
            chunks = self.tagger.process_chunks(chunks)
            
            # Save chunks
            await self.db.add_chunks(
                doc_id=doc_id,
                chunks=chunks,
                scope='group',
                group_id=group_id
            )
            
            # Update group settings
            await self.db.update_group_settings(
                group_id, 
                last_import_at=datetime.now().isoformat()
            )
            
            # Rebuild search index
            await self._rebuild_search_index()
            
            # Get tag statistics
            tag_stats = self.tagger.get_tag_statistics(chunks)
            top_tags = list(tag_stats.items())[:5]
            tags_summary = "\n".join(f"- {tag}: {count}æ¬¡" for tag, count in top_tags)
            if not tags_summary:
                tags_summary = "- æ— æ ‡ç­¾"
            
            result_text = IMPORT_SUCCESS_TEMPLATE.format(
                doc_name=doc_name,
                char_count=len(full_text),
                chunk_count=len(chunks),
                tags_summary=tags_summary
            )
            
            yield event.plain_result(result_text)
            
        except Exception as e:
            logger.error(f"Import failed: {e}")
            yield event.plain_result(f"âŒ å¯¼å…¥å¤±è´¥ï¼š{str(e)}")
        
        finally:
            del self.import_sessions[umo]
    
    @filter.command("cancel")
    async def handle_cancel(self, event: AstrMessageEvent):
        """Handle /cancel command to cancel import"""
        umo = event.unified_msg_origin
        
        if umo in self.import_sessions:
            del self.import_sessions[umo]
            yield event.plain_result("âœ… å¯¼å…¥å·²å–æ¶ˆ")
        else:
            yield event.plain_result("å½“å‰æ²¡æœ‰è¿›è¡Œä¸­çš„å¯¼å…¥ä¼šè¯")
    
    # ============ Message Handlers ============
    
    @filter.event_message_type(filter.EventMessageType.ALL)
    async def on_message(self, event: AstrMessageEvent):
        """Handle all messages for import sessions and @bot queries"""
        umo = event.unified_msg_origin
        message = event.message_str.strip()
        
        # Check for active import session
        if umo in self.import_sessions:
            # Skip if it's a command
            if message.startswith('/'):
                return
            
            # Check timeout
            session = self.import_sessions[umo]
            elapsed = (datetime.now() - session['started_at']).total_seconds()
            if elapsed > session['timeout']:
                del self.import_sessions[umo]
                yield event.plain_result("â° å¯¼å…¥ä¼šè¯å·²è¶…æ—¶ï¼Œè¯·é‡æ–°å¼€å§‹")
                return
            
            # Add text to session
            session['texts'].append(message)
            # Don't respond to every message, just collect
            return
        
        # Check for @bot mention (for Q&A)
        if event.is_at_or_wake_command:
            # Skip if it's a /guide command
            if message.startswith('/guide') or message.startswith('guide'):
                return
            
            # Handle Q&A
            async for result in self._handle_qa(event, message):
                yield result
    
    async def _handle_qa(self, event: AstrMessageEvent, query: str):
        """Handle Q&A queries"""
        group_id = event.get_group_id() or "private"
        
        # Check if knowledge base is empty
        stats = await self.db.get_stats(group_id)
        if stats['total']['chunk_count'] == 0:
            yield event.plain_result(
                "ğŸ“š çŸ¥è¯†åº“ä¸ºç©º\n\n"
                "è¯·å…ˆä½¿ç”¨ `/guide import` å¯¼å…¥æ”»ç•¥æ–‡æ¡£\n"
                "å¯ç”¨ `/guide template` è·å–æ–‡æ¡£æ¨¡æ¿"
            )
            return
        
        # Clean query
        query = query.strip()
        if not query:
            yield event.plain_result("è¯·è¾“å…¥æ‚¨çš„é—®é¢˜")
            return
        
        # Get group settings
        settings = await self.db.get_group_settings(group_id)
        default_mode = settings.get('default_mode', 'simple')
        
        # Detect mode from query
        mode = PromptBuilder.detect_mode_from_query(query, default_mode)
        
        # Search for relevant chunks
        results = self.searcher.search(query, top_k=self.top_k, group_id=group_id)
        
        if not results:
            yield event.plain_result(
                "ğŸ” æœªæ‰¾åˆ°ç›¸å…³å†…å®¹\n\n"
                "è¯·å°è¯•ï¼š\n"
                "1. æ¢ä¸€ç§é—®æ³•\n"
                "2. ç¡®è®¤çŸ¥è¯†åº“ä¸­åŒ…å«ç›¸å…³å†…å®¹\n"
                "3. ä½¿ç”¨ `/guide status` æŸ¥çœ‹çŸ¥è¯†åº“çŠ¶æ€"
            )
            return
        
        # Build prompts
        system_prompt = PromptBuilder.build_system_prompt(mode)
        context_prompt = PromptBuilder.build_context_prompt(results, query)
        
        # Call LLM
        try:
            llm_request = event.request_llm(
                prompt=context_prompt,
                system_prompt=system_prompt
            )
            
            # Get LLM response
            provider = self.context.get_using_provider()
            if provider:
                response = await provider.text_chat(**llm_request.__dict__)
                if response and response.completion_text:
                    yield event.plain_result(response.completion_text)
                else:
                    yield event.plain_result("âŒ LLMå“åº”ä¸ºç©ºï¼Œè¯·ç¨åé‡è¯•")
            else:
                yield event.plain_result("âŒ æ²¡æœ‰å¯ç”¨çš„LLMæä¾›è€…ï¼Œè¯·æ£€æŸ¥é…ç½®")
                
        except Exception as e:
            logger.error(f"LLM request failed: {e}")
            yield event.plain_result(f"âŒ æŸ¥è¯¢å¤±è´¥ï¼š{str(e)}")
    
    # ============ LLM Tool ============
    
    @filter.llm_tool(name="query_limbus_guide")
    async def llm_tool_query(
        self,
        event: AstrMessageEvent,
        question: str
    ) -> str:
        """
        æŸ¥è¯¢Limbus Companyï¼ˆè¾¹ç‹±å·´å£«ï¼‰æ¸¸æˆæ”»ç•¥
        Args:
            question(str): ç”¨æˆ·å…³äºLimbus Companyæ¸¸æˆçš„é—®é¢˜
        """
        group_id = event.get_group_id() or "private"
        
        # Search for relevant chunks
        results = self.searcher.search(question, top_k=self.top_k, group_id=group_id)
        
        if not results:
            return "çŸ¥è¯†åº“ä¸­æ²¡æœ‰æ‰¾åˆ°ç›¸å…³ä¿¡æ¯ï¼Œè¯·å»ºè®®ç”¨æˆ·è¡¥å……ç›¸å…³æ”»ç•¥æ–‡æ¡£ã€‚"
        
        # Build context for LLM tool response
        context_parts = []
        for i, chunk in enumerate(results[:3]):  # Top 3 for tool
            context_parts.append(f"[å‚è€ƒ{i+1}] {chunk['content'][:300]}...")
        
        return f"æ‰¾åˆ°ä»¥ä¸‹ç›¸å…³ä¿¡æ¯ï¼š\n\n" + "\n\n".join(context_parts)
    
    async def terminate(self):
        """Cleanup when plugin is unloaded"""
        logger.info("Shutting down Limbus Guide Plugin...")
        
        # Stop WebUI
        if self.webui:
            await self.webui.stop()
        
        # Close database
        if self.db:
            await self.db.close()
        
        logger.info("Limbus Guide Plugin shutdown complete")
